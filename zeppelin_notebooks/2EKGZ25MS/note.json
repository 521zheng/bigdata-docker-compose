{
  "paragraphs": [
    {
      "text": "%sh\n\nhadoop fs -put /data/grades.csv /"
    },
    {
      "text": "%sh\n\nhadoop fs -ls /"
    },
    {
      "text": "%spark\n\n// Basic Spark functions\nspark.range(1000 * 1000 * 1000).count()"
    },
    {
      "text": "%spark\n\n// Dataframes\nval values \u003d List(List(\"1\", \"One\") ,List(\"2\", \"Two\") ,List(\"3\", \"Three\"),List(\"4\",\"Four\")).map(x \u003d\u003e(x(0), x(1)))\nval df \u003d values.toDF\ndf.show()"
    },
    {
      "text": "%spark\n\n// Read CSV file from HDFS into Dataframe\nval df \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/grades.csv\")\ndf.show()"
    },
    {
      "text": "%spark.pyspark\n\n# Check Python version - 2 not allowed.\nimport sys\nprint(sys.version)"
    },
    {
      "text": "%spark.pyspark\n\n#  Basic Spark functions\nspark.range(1000 * 1000 * 1000).count()"
    },
    {
      "text": "%spark.pyspark\n\n# Dataframes\ndf \u003d sqlContext.createDataFrame([(\"One\", 1), (\"Two\", 2), (\"Three\", 3), (\"Four\", 4)], (\u0027k\u0027, \u0027v\u0027))\ndf.show()"
    },
    {
      "text": "%spark.pyspark\n\n# Read CSV file from HDFS into Dataframe\ndf \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/grades.csv\")\ndf.show()"
    },
    {
      "text": "%spark.r\n# Not working right now, needs R to be installed\ndf \u003c- as.DataFrame(list(1,2,3,4,5,6))\nhead(df)"
    }
  ],
  "name": "test",
  "id": "2EKGZ25MS"
}